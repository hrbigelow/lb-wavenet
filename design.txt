A TF implementation of "WaveNet: A Generative Model for Raw Audio"

Overall Structure of the model

The input r = { r_1, r_2, ..., r_T } for some number of time steps.
Each r_t is a 16-bit number in [-1, 1] from the raw audio waveform.

It is then companded as x_t = sign(r_t){ln(1 + abs(r_t) * mu) / ln(1 + mu)}
Then, it is quantized into 256 values.

It is either fed to the network as a number (0-255 or floating-point in [-1, 1]?)
or encoded by an 8-bit binary vector.

The next step is just diagrammed as a box called 'causal conv', which  is strange
because all convolutions in this network are called "causal".

It's not clear from the paper what The next step is just diagrammed as a box called 'causal conv', which  is strange
because all convolutions in this network are called "causal".

It's not clear from the paper what The next step is just diagrammed as a box called 'causal conv', which  is strange
because all convolutions in this network are called "causal".

It's not clear from the paper what 
